  \noindent\textbf{CP Contributed session 1}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{The projection onto the 1-infinity ball (P1-infty) has been applied in
cognitive neuroscience and classification tasks, and it is an example
of mixed norms, which recently have gained popularity for inducing
group sparsity priors in several applications. We present a new
algorithm, eight times faster than the state-of-the-art, to solve the
P1-infty for which we have derived an analytical expression that
allows us to apply Newton’s root-finding method along with an
effective pruning strategy.}\\
\\ 
        \myaut{  Gustavo Chau}\\
        \mail{gustavo.chau@pucp.edu.pe}\\\\
        \myaut{  Brendt Wohlberg}\\
        \mail{brendt@ieee.org}\\\\
        \myaut{*   Paul Rodriguez}\\
        \mail{prodrig@pucp.edu.pe}\\\\
\\
      \textit{We propose a novel and computationally efficient algorithm for improving the alternating optimization (AO) of the nonconvex l0 sparse approximation (l0-SpApp) problem. Given an initial solution, our two-step iterative method consists on first finding the vanilla AO solution to l0-SpApp, to then element-wise scale it; this procedure avoids being trapped or getting stuck in saddle points or inferior local solutions respectively. Our proposed algorithm is simple to code and faster than the state-of-the-art for l0-SpApp.}\\
\\ 
        \myaut{*   Paul Rodriguez}\\
        \mail{prodrig@pucp.edu.pe}\\\\
\\
      \textit{Many tasks in imaging can be modeled as the minimization of non-convex composite functions. Interpreting previous optimization methods as majorization-minimization algorithms show that convex majorizers were previously considered. Yet, certain classes of non-convex majorizers still allow solving each sub-problem to (near)-optimality, leading to a provably convergent optimization scheme.
Numerical results illustrate that by applying this scheme, one can achieve superior local optima compared to descent methods, while being significantly more efficient than global optimization methods.}\\
\\ 
        \myaut{*   Jonas Geiping}\\
        \mail{jonas.geiping@uni-siegen.de}\\\\
        \myaut{  Michael Moeller}\\
        \mail{michael.moeller@uni-siegen.de}\\\\
\\
      \textit{[1] introduces a new class of proximal splitting algorithms that 
differ from existing methods in that they are both block-iterative 
and asynchronous, and allow for individual conditioning of the 
functions. We present the first numerical applications of the
method to imaging, and discuss how its flexibility leads to
extremely fast implementations.  Extensive numerical simulations
are provided. Joint work with L.  Glaudin.
[1] P. Combettes and J. Eckstein, Asynchronous block-iterative
decomposition.., Mathematical Programming, 2017.}\\
\\ 
        \myaut{*   Patrick Combettes}\\
        \mail{plc@math.ncsu.edu}\\\\
\\
      \textit{When using block iterative methods or their regularized version for solving inverse problems with noisy data, we encounter a phenomenon that is called semi-convergence. To control the mentioned phenomenon, unlike the recent studies, we assume that relaxation parameters depend on the noise and we suggest an efficient non-stationary strategy for picking relaxation parameters which suppresses the noise propagation during iterations. The performance of the suggested strategy will be illustrated by examples obtained from tomography imaging.}\\
\\ 
        \myaut{*   Mahdi Mirzapour}\\
        \mail{mahdimirzapour67@gmail.com}\\\\
\\
      \textit{Inspired by recent advances in machine learning, and in particular by the concept of learning an optimizer, we investigate a class of proximal primal-dual optimizers with a fixed amount of memory. We derive convergence criteria and find several sub-classes corresponding to classical optimization methods such as Chambolle-Pock and Douglas-Rachford methods. Finally, we discuss the choice of algorithm instances for concrete problems.}\\
\\ 
        \myaut{*   Sebastian Banert}\\
        \mail{banert@kth.se}\\\\
        \myaut{  Jonas Adler}\\
        \mail{jonasadl@kth.se}\\\\
        \myaut{  Johan Karlsson}\\
        \mail{johan.karlsson@math.kth.se}\\\\
        \myaut{  Ozan  Öktem}\\
        \mail{ozan@kth.se}\\\\
        \myaut{  Axel Ringh}\\
        \mail{aringh@kth.se}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 2}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{The image classifier consists of two interacting modules: feature extraction and linear classification. Feature extraction relies on evaluating spatial derivatives of integer or fractional order of the image, followed by non-linear transformations in the Fourier domain. Linear classification relies on multivariate statistical analysis of feature vectors. Training minimizes a loss function: the latter depends on the parameter n-tuple which controls feature extraction. Application: discrimination of bacterial spores among airborne particulate material.}\\
\\ 
        \myaut{*   Giovanni Franco Crosta}\\
        \mail{giovanni\_crosta@uml.edu}\\\\
\\
      \textit{The Hurst parameter of a fractional Brownian motion (fBm) on a smooth manifold determines the regularity of the corresponding
fractional Brownian surface (fBs). Estimating the regularity of a given fBs is difficult since the underlying fBm is unknown. We propose here the first spectral-regression algorithm to estimate the Hurst parameter of a given fBs. The algorithm is evaluated on a set of simulated fractional Brownian spheres and we present an application to brain surfaces.}\\
\\ 
        \myaut{*   Hamed Rabiei}\\
        \mail{hamed.rabiei10@gmail.com}\\\\
        \myaut{  Frédéric Richard}\\
        \mail{frederic.richard@univ-amu.fr}\\\\
        \myaut{  Julien  Lefèvre}\\
        \mail{julien.lefevre@univ-amu.fr}\\\\
        \myaut{  Olivier Coulon}\\
        \mail{olivier.coulon@univ-amu.fr}\\\\
\\
      \textit{We propose an automatic and unsupervised method for the segmentation of colonic polyps for   in vivo  Narrow-Band-Imaging (NBI) data, during optical colonoscopy,  aiming at the prevention of colon cancer.
 The method is based on the Chan \& Vese segmentation model and involves the sum of different Wasserstein distances, relying on histograms of suitable image descriptors, such as the intensity, texture, scale and orientation.}\\
\\ 
        \myaut{*   Isabel Figueiredo}\\
        \mail{isabelf@mat.uc.pt}\\\\
        \myaut{  Luís Pinto}\\
        \mail{luisp@mat.uc.pt}\\\\
        \myaut{  Pedro Figueiredo}\\
        \mail{pnf11@sapo.pt}\\\\
        \myaut{  Richard Tsai}\\
        \mail{ytsai@math.utexas.edu}\\\\
\\
      \textit{In this paper, we propose a method for minimization of segmentation model for vector-valued texture images. The texture in the image will be smooth by using $L\_0$ gradient norm and then the segmentation model will be minimized through sobolev gradient for fast convergence. The better performance of the method will observed from the experimental results. Results of the proposed method are compared with $L^2$ gradients.}\\
\\ 
        \myaut{*   Fahim Ullah}\\
        \mail{fahim.lne@uetpeshawar.edu.pk}\\\\
        \myaut{  Noor  Badshah}\\
        \mail{noor2knoor@gmail.com}\\\\
        \myaut{  Hassan Shah}\\
        \mail{hassanshah.edu@gmail.com}\\\\
\\
      \textit{The filtered back projection formula allows to reconstruct bivariate functions from given Radon samples, where low-pass filters of finite bandwidth are employed to stabilize the reconstruction. Our aim is to analyze the inherent approximation error incurred by the low-pass filter. We prove error estimates in fractional Sobolev spaces along with asymptotic convergence rates as the bandwidth goes to infinity, where we observe saturation at fractional order depending on smoothness properties of the filter's window function.}\\
\\ 
        \myaut{*   Matthias Beckmann}\\
        \mail{matthias.beckmann@uni-hamburg.de}\\\\
        \myaut{  Armin Iske}\\
        \mail{armin.iske@uni-hamburg.de}\\\\
\\
      \textit{In this talk, we propose a novel model for the shape prior segmentation that produces robust results using the hierarchical image segmentation and an attraction term. Moreover, we adopt an image registration technique and a multi-region image segmentation to get an initial for a given shape prior. Finally, we consider the free-form deformation in obtaining the shape function from the reference shape prior for real-world images.}\\
\\ 
        \myaut{*   Chang-Ock Lee}\\
        \mail{colee@kaist.edu}\\\\
        \myaut{  Doyeob Yeo}\\
        \mail{greatday327@gmail.com}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 3}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{Most often medical images such as chest radiographs have low dynamic range and many of their targeted features are difficult to identify. Intensity transformations such as wavelet thresholding that improve image quality introduces unwanted artifacts into the image. A combined total variation-undecimated wavelet enhancement algorithm that leads to a high level chest radiograph image denoising in lung nodules detection while preserving important features and reducing the average number of false positives and false negatives is proposed.}\\
\\ 
        \myaut{*   Anthony  Aidoo}\\
        \mail{aidooa@easternct.edu}\\\\
\\
      \textit{I will consider X-ray tomography in a product of an interval and a Euclidean space of any dimension. If one does not assume compact support or suitable decay, the X-ray transform has a non-trivial kernel. I will characterize the kernel for periodic functions. I will also discuss tensor tomography. The kernel consists of tensor fields of two kinds, and it can be fully characterized. This is based on joint work with Gunther Uhlmann.}\\
\\ 
        \myaut{*   Joonas Ilmavirta}\\
        \mail{joonas.ilmavirta@jyu.fi}\\\\
\\
      \textit{In this talk, we focus on dynamic Positron Emission data reconstruction.  We present regularization methods that are based on different edge preserving priors adapted to problems corrupted by Poisson noise. In particular, we consider spatiotemporal Total Variation (TV), Total Generalised Variation (TGV) reconstructions and their extensions to the infimal convolution approach as proposed by Holler and Kunisch. The numerical solutions of the corresponding variational problems are evaluated using Primal-Dual Hybrid Gradient (PDHG) optimisation methods under diagonal preconditioning. We compare them with the state of the art techniques as Expectation Maximization (EM) reconstruction and Filtered backprojection for simulated dynamic brain data. This is a joint work with Clovis Tauber (INSERM, Tours) and Maïtine Bergounioux (MAPMO, Orléans).}\\
\\ 
        \myaut{*   Evangelos  Papoutsellis}\\
        \mail{epapoutsellis@gmail.com}\\\\
        \myaut{  Clovis Tauber}\\
        \mail{clovis.tauber@univ-tours.fr}\\\\
        \myaut{  Maïtine  Bergounioux}\\
        \mail{maitine.bergounioux@univ-orleans.fr}\\\\
\\
      \textit{Total variation and high order total variation methods for image reconstruction rely on sparsity throughout some domain. The spatial variation of the sparsity is not typically accounted for, however. We propose a new method for image reconstruction from non-uniform Fourier data that uses edge detection to indicate regions of sparsity and targets regularization appropriately.}\\
\\ 
        \myaut{*   Victor Churchill}\\
        \mail{victor.a.churchill.gr@dartmouth.edu}\\\\
        \myaut{  Anne Gelb}\\
        \mail{anne.e.gelb@dartmouth.edu}\\\\
        \myaut{  Richard Archibald}\\
        \mail{archibaldrk@ornl.gov}\\\\
\\
      \textit{Quantitative photoacoustic tomography is an imaging technique that estimates choromophore concentrations by combining optical information and the ultrasonic waves that arise from the photoacoustic effect. The discontinuous Galerkin method is used to the model photoacoustic wave propagation in a fluid with an elastic layer. Inversion is done within the Bayesian framework using adjoint wavefields. Bayesian approximation error approach is used to marginalise over the geometry of the elastic layer.}\\
\\ 
        \myaut{*   Hwan Goh}\\
        \mail{hgoh009@aucklanduni.ac.nz}\\\\
\\
      \textit{In ultrasound tomography, we need to solve the inverse and the forward model to approximate a scattering function. This inverse scattering problem is constructed and solved using distorted Born iterative (DBI) method.  Using the Born approximation (BA) as an initial guess, it solves three sub-problems, the most difficult of which is an inverse problem for the scattering function.  Two truncated total least squares algorithms are considered for solving a regularized version of this inverse problem.}\\
\\ 
        \myaut{*   Jesse Barlow}\\
        \mail{barlow@cse.psu.edu}\\\\
        \myaut{  Anita  Carevic'}\\
        \mail{carevica@fesb.hr}\\\\
        \myaut{  Mohamed Almekkaway}\\
        \mail{mka9@psu.edu}\\\\
        \myaut{  Xingzhao Yun}\\
        \mail{xuy43@psu.edu}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 4}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{Magnetic resonance fingerprinting (Ma et al, Nature, 2013) is a method for estimating multiple spatially varying medium parameters from a single MRI experiment. It differs from standard MRI in that spins are not brought to a stationary state, as RF flip angles and repetition times may vary during the entire experiment.  We will discuss a mathematical model for MRF imaging and a quantitative basis for the choice of the various parameters.}\\
\\ 
        \myaut{*   Chris Stolk}\\
        \mail{c.c.stolk@uva.nl}\\\\
\\
      \textit{We present CORVO (Computing Organoids’ VOlume in medical images), a tool for calculating the volume of complex time-changing 3D structure from medical images and/or videos. CORVO is equipped with an advanced statistical data processing method to distinguish noise from signal and to compare and analyze the time dynamics of 3D structures. We tested CORVO for the analysis of agonist-induced variation of rectal organoids volume.}\\
\\ 
        \myaut{*   Paola Lecca}\\
        \mail{paola.lecca@unitn.it}\\\\
        \myaut{  Michela Lecca}\\
        \mail{lecca@fbk.eu}\\\\
        \myaut{  Sara Caldrer}\\
        \mail{saracaldrer@gmail.com}\\\\
        \myaut{  Anna Baruzzi}\\
        \mail{anna.baruzzi@gmail.com}\\\\
        \myaut{  Claudio Sorio}\\
        \mail{claudio.sorio@univr.it}\\\\
        \myaut{  Paola Melotti}\\
        \mail{paola.melotti@aovr.veneto.it}\\\\
\\
      \textit{Electric properties tomography of human bodies from measurements performed by magnetic resonance imaging (MRI) is an innovative research field emerged in last years and denoted as MREPT. The accuracy of most MREPT approaches proposed in literature suffers from the impossibility of measuring the phase of the MRI transmit coil sensitivity. A variation of the contrast source inversion technique for MREPT, specifically conceived to work without the phase information, will be described.}\\
\\ 
        \myaut{*   Alessandro Arduino}\\
        \mail{alessandro.arduino@polito.it}\\\\
        \myaut{  Luca Zilberti}\\
        \mail{l.zilberti@inrim.it}\\\\
        \myaut{  Oriano Bottauscio}\\
        \mail{o.bottauscio@inrim.it}\\\\
        \myaut{  Mario Chiampi}\\
        \mail{mario.chiampi@polito.it}\\\\
\\
      \textit{Detecting and treating tumors in early stages is key to reducing cancer mortality. We present automatic classification techniques for breast lesions in screening mammography. The images undergo data augmentation, preprocessing with global and local contrast normalizations, and then combined with various scales of rotationally symmetric Laplacian of Gaussian filters. We employ the deep convolutional neural networks to extract the discriminative information from the data, and characterize benign and malignant lesions. The performance is compared against the state-of-the-art image descriptors, such as HOG and SVM.}\\
\\ 
        \myaut{*   Jue Wang}\\
        \mail{wangj@union.edu}\\\\
        \myaut{  Yongjian Yu}\\
        \mail{yongjian.yu@axonconnected.com}\\\\
\\
      \textit{The present work investigates the physical feasibility of an electromagnetic ultrasound transducer, with central frequency in the range of 40 to 60 kHz, to be used in ultrasound tomography for lung monitoring. The transducer is composed of a cup and a top closing plate and a solenoid. The top plate is connected to the cup by an elastic material. The acoustic field, the longitudinal stiffness and the behavior in a biological tissue are simulated.}\\
\\ 
        \myaut{*   Raul Gonzalez Lima}\\
        \mail{rauglima@usp.br}\\\\
        \myaut{  Luis Henrique Camargo Quiroz}\\
        \mail{luishcq@usp.br}\\\\
        \myaut{  Ely Lopes}\\
        \mail{ely.lopes@usp.br}\\\\
\\
      \textit{PET-CT, PET-MR, or SPECT-CT allows simultaneous acquisition of functional and structural images which facilitates spatial localization of physiological processes to physical organs or ROIs. However, resolution is severely degraded by physical factors that compromise quantitative accuracy of functional parameters. The resolution and SNR could be boosted by utilizing complementary/correlated information from co-registered, high-resolution structural images. The high-resolution image is resampled to obtain voxel-wise correspondences. This work explores the impact of resampling strategies in medical imaging.}\\
\\ 
        \myaut{*   Hassan Mohy-ud-Din}\\
        \mail{mohyuddin.engineer@gmail.com}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 5}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{We consider a functional proposed by Lauze and Nielsen (2004) for motion compensated inpainting and recently applied by the same authors to problems of video deinterlacing (2008) and video super-resolution (2011). 
We modify their model in order to achieve better variational properties and we study the corresponding relaxed functional, wich gives information about numerical algorithms designed for the original functional.
Minimizers of the relaxed functional are vector valued functions of bounded variation, so that a video content which is discontinuous along the boundaries of moving objects can be reconstructed. Moreover, we find a representation formula of the relaxed functional which shows explicitly the role of discontinuities of the various functions involved in the variational model.
Joint work with R. March.}\\
\\ 
        \myaut{*   Giuseppe Riey}\\
        \mail{riey@mat.unical.it}\\\\
\\
      \textit{Motion blur usually happens to image recording systems. Nowadays, this rich source of data is mostly dismissed in favor of image restoration. We introduce a novel approach for estimating kinematic quantities such as direction and speed of motion using the Discrete Cosine Transform (DCT). The mean relative error of our DCT PSeudo Cepstrum for speed estimation was 5.15%. The DCT frequency analysis is more accurate than all competitors evaluated.}\\
      }
\\ 
        \myaut{*   Jimy Alexander Cortes}\\
        \mail{jacoper@utp.edu.co}\\\\
        \myaut{  Juan Bernardo Gómez}\\
        \mail{jbgomezm@unal.edu.co}\\\\
        \myaut{  Juan Carlos Riaño}\\
        \mail{jcrianoro@unal.edu.co}\\\\
\\
      \textit{Following the first promising preliminary results, we study different strategies for the extension to color images of the Wavelet Normalised Root Mean Squared Error (WNRMSE), a new image similarity assessment metric, previously introduced and extensively studied by the authors for monochromatic images. The theoretical properties of the resulting color image metrics are studied, and the different extension strategies are tested and compared on the standard benchmark database TID2013. }\\
\\ 
        \myaut{*   Silvia Bertoluzza}\\
        \mail{silvia.bertoluzza@imati.cnr.it}\\\\
        \myaut{  Riccardo Amadeo}\\
        \mail{riccardo.amadeo@gmail.com}\\\\
        \myaut{  Maria Grazia Albanesi}\\
        \mail{mariagrazia.albanesi@unipv.it}\\\\
\\
      \textit{We show that the cone-adapted shearlet coefficients can be computed by means of three classical transforms: the affine Radon transform, a 1D wavelet transform and a 1D convolution. This yields formulas that open new perspectives both for finding a new algorithm to compute shearlet coefficients and for the inversion of the Radon transform. Furthermore, the strong connection between shearlets and wavelets suggests an alternative proof of the wavefront set resolution properties of the shearlet transform. }\\
\\ 
        \myaut{*   Francesca  Bartolucci}\\
        \mail{bartolucci@dima.unige.it}\\\\
        \myaut{  Ernesto De Vito}\\
        \mail{devito@dima.unige.it}\\\\
        \myaut{  Filippo De Mari}\\
        \mail{demari@dima.unige.it}\\\\
        \myaut{  Francesca  Odone}\\
        \mail{francesca.odone@unige.it}\\\\
\\
      \textit{In this communication we present a coherent interferometric (CINT) imaging algorithm to localize acoustic sources in random fluid flows. It uses empirical correlations of the acoustic waves recorded at the bottom of the flow to possibly locate the sources emitting the waves above it. We rely on an analytical model of wave transmission in randomly stratified fluid flows to develop the algorithm. This model is established in a particular regime of separation of scales.}\\
\\ 
        \myaut{*   Etienne Gay}\\
        \mail{etienne.gay@onera.fr}\\\\
\\
      \textit{Given a multiscaling function with symbol $H(z)$, its low-pass product
filter has the symbol $P(z) = H(z) H(z)^*$. We are interested in
finding $H(z)$, given a $P(z)$ with desirable features. Unfortunately,
desirable $P(z)$ cause numerical problems with the factorization
algorithm. 
I will describe the setup of the problem, and various attempts to speed up
its convergence and improve accuracy.}\\
\\ 
        \myaut{*   Fritz Keinert}\\
        \mail{keinert@iastate.edu}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 6}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{Recently we published a new image compression method utilizing a combination of discrete cosine transform and least squares interpolation method. In this talk, we will present a discussion of the mathematical background, outline of the approach, complexity computations, pseudocode, and an explanation of how to implement the algorithm for applications that require the coded bits to be binary streams. We then provide the results, including comparisons to many recently published works. Also, we compare our work versus both JPEG and JPEG 2000, where we have significant improvement. The results indicate positive progress and effectiveness of the new approach in terms of comparability to other works and applicability in real time applications.}\\
\\ 
        \myaut{*   Sameh  Eisa}\\
        \mail{seisa@uci.edu}\\\\
\\
      \textit{The image compression based on principal component analysis  is a well-established fundamental technique. 
Organs, cells and micro-structures in cells dealt with in biomedical image analysis are volumetric images. 
Tensor expression of volumetric images allows us to derive unified frameworks to process and analyse 
these volumetric images dealt with in medical and biological sciences.  
We develop a fast approximate tensor principal component analysis 
for volumetric images by using tensor decomposition. }\\
\\ 
        \myaut{*   Atsushi  Imiya}\\
        \mail{imiya@faculty.chiba-u.jp}\\\\
\\
      \textit{A nonlinear optimization method is proposed for inverse scattering problems in
the frequency domain, when the unknown medium is characterized by one or several
spatially varying parameters. The time-harmonic inverse medium problem is formulated 
as a PDE-constrained optimization problem and solved by an inexact truncated
Newton-type method combined with frequency stepping. Instead of a grid-based 
discrete representation combined with standard Tikhonov-type regularization, 
each parameter is projected to a (small and slowly increasing) finite-dimensional
subspace, which is iteratively adapted during the optimization. }\\
\\ 
        \myaut{*   Marcus Grote}\\
        \mail{marcus.grote@unibas.ch}\\\\
        \myaut{  Uri Nahum}\\
        \mail{uri.nahum@unibas.ch}\\\\
\\
      \textit{Krylov subspace methods are powerful iterative regularization tools for large-scale linear inverse problems, such as those arising in image deblurring and computed tomography. We exploit a flexible version of some Krylov subspace methods, which uses adaptive preconditioning to promote TV-like regularization in the solution. Numerical experiments and comparisons with other well-known methods for the computation of large-scale solutions are presented. }\\
\\ 
        \myaut{*   Malena Sabate Landman}\\
        \mail{m.sabate.landman@bath.ac.uk}\\\\
        \myaut{  Silvia Gazzola}\\
        \mail{s.gazzola@bath.ac.uk}\\\\
\\
      \textit{ Many unsupervised learning algorithms provide dimensionality reduction (DR), among which the diffusion mapping is proved attractive and effective. However, these method cannot be straightforwardly applied for DR of new coming set. The out-of-sample extension is to find DR of the new set using an extension technique based on the same DR method for the training set. Many papers have developed out-of-extension algorithms based on Nystrom approximation and shown their validity by numerical experiments. However, the mathematical theory for the extension still need a further consideration.  Based on the reproducing kernel Hilbert space (RKHS) theory, we give a mathematical analysis on such out-of-sample extensions. We treat an out-of-sample extension operator as an extension of the identity on the RKHS. Then the Nystrom-type extension becomes an orthogonal embedding on the RKHS. We then present the conditions for the exact extension and estimate the errors of the extensions.}\\
\\ 
        \myaut{*   Jianzhong Wang}\\
        \mail{jzwang@shsu.edu}\\\\
\\
      \textit{We propose a new image denoising algorithm by incorporating the $L\_1$-regularization technique and the least squares method. In order to improve the quality of the reconstructed images, we adopt a high order least squares method along with new iterative nonlocal weights. In particular, we devise a measurement to estimate the nonlocal similarities between patches by using both data values and their derivatives. Some experimental results are presented to demonstrate the capability of the proposed algorithm.
}\\
\\ 
        \myaut{  Byeongseon Jeong}\\
        \mail{bjeongle@gmail.com}\\\\
        \myaut{  Yunjin Park}\\
        \mail{yunjjiin@naver.com}\\\\
        \myaut{*   Hyoseon Yang}\\
        \mail{hyoseon1989@gmail.com}\\\\
        \myaut{  Jungho Yoon}\\
        \mail{yoon@ewha.ac.kr}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 7}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{The recognition of objects in digital images is a  key problem  in computer vision. It has received the attention of many researchers  in order to evaluate and improve the performance of descriptors but mainly the shape descriptor.
		In this talk, we will consider the persistent homology which is an algebraic tool to measure the topological features of shapes of high dimensional data. We use complexes to represent continuous spaces and specially the cubical complexes that are considered the basis of digital images. Using cubical complexes inside of triangulation  reduce significantly the size of complexes. We represent this algebraic characterization as bare-codes that are a finite union of intervals and which are considered the shape descriptor. The benefits of this approach will be presented at the last section of this talk in the Arabic handwriting recognition using structural and syntactic pattern attributes.}\\
\\ 
        \myaut{*   My Ismail Mamouni}\\
        \mail{mamouni.myismail@gmail.com}\\\\
\\
      \textit{We compare different unsupervised approaches to quantify the width of elongated structures in biological images. Two approaches detect first the centerline of the structure and rely on topological asymptotics of various cost functions and a fourth order elliptic PDE. The other approaches aim at detecting directly the boundaries of the structures: the gold standard is Canny's edge detector, and the last is based on topological asymptotics of a second order elliptic PDE.}\\
\\ 
        \myaut{*   Fehrenbach Jerome}\\
        \mail{jerome.fehrenbach@math.univ-toulouse.fr}\\\\
        \myaut{  de Gournay Frederic}\\
        \mail{frederic.de-gournay@insa-toulouse.fr}\\\\
\\
      \textit{We have proposed a denoising method by combining shearlet transform method  and  weighted  Yaroslavsky’s  filter  (YF)  for  a  wide  class  of  cartoon  like images with various properties such as thin features and naturalistic. The weights of the Yaroslavsky’s filter are also achieved by pixel similarities in the restored image achieved from shearlet transform method. The theoretical results are confirmed via simulations for images corrupted by additive white Gaussian noise. Experimental 
results illustrate that proposed approach has good effect on suppressing the pseudo-Gibbs and shearlet-like artifacts and can obtain better performance in terms of mean square  error  (MSE),  peak  signal  to noise  ratio  (PSNR)  and  structural  similarity 
(SSIM) index rather than classical shearlet transform method.}\\
\\ 
        \myaut{*   Reza Abazari}\\
        \mail{abazari.r@tabrizu.ac.ir}\\\\
        \myaut{  Mehrdad Lakestani}\\
        \mail{lakestani@tabrizu.ac.ir}\\\\
\\
      \textit{We introduce a generalized l1 greedy algorithm for recovering sparse signals and demonstrate its superior performance over the classical reweighted l1 minimization algorithm (Candes, et. al) and the l1 greedy algorithm (Petukhov and Kozlov). Moreover, we show our algorithm is better at detecting small entries of unknown sparse signals thereby dramatically speeding up their recovery via l1 minimization. Finally, we discuss how to improve our algorithm by adapting the wavelet technique of semisoft thresholding.}\\
\\ 
        \myaut{*   Fangjun Arroyo}\\
        \mail{farroyo@fmarion.edu}\\\\
        \myaut{  Edward Arroyo}\\
        \mail{edward.arroyo@northwestern.edu}\\\\
\\
      \textit{Usual methods for dictionary learning applied to multidimensional data require a first vectorization step, loosing the intrinsic spatial correlation of the samples. We present a method based on a generalization of the Haar wavelet transform that builds a dictionary from a hierarchical clustering of the data. Depending on the chosen clustering method, no vectorization of the data is required. We will present numerical results in the case of two dimensional patches extracted from natural images.}\\
\\ 
        \myaut{*   Renato Budinich}\\
        \mail{r.budinich@math.uni-goettingen.de}\\\\
        \myaut{  Gerlind Plonka}\\
        \mail{plonka@math.uni-goettingen.de}\\\\
\\
      \textit{Tensor-based dictionary learning is a natural approach to form accurate, compressible representations of high-dimensional data (Soltani, Kilmer, Hansen, BIT 2016).  In this talk, we explore the generalizability of these tensor dictionaries for image reconstruction problems.  For instance, can a dictionary learned from a certain class of images be used to reconstruct a wider variety of images?  To reconstruct images efficiently and sparsely from tensor dictionaries, we present a tensor-based Modified Residual Norm Steepest Descent algorithm.}\\
\\ 
        \myaut{*   Elizabeth Newman}\\
        \mail{e.newman@tufts.edu}\\\\
        \myaut{  Misha Kilmer}\\
        \mail{misha.kilmer@tufts.edu}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 8}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{Functional magnetic resonance imaging (fMRI) is an imaging modality widely used to study physiological processes. State estimation methods can be used to reconstruct fMRI images even from highly undersampled data. Using conventional radial sampling, however, can cause suboptimal results with state estimation methods. In this talk we present an alternative radial sampling method based on golden angle. This method allows for improved results compared to conventional radial sampling when using state estimation methods. }\\
\\ 
        \myaut{*   Ville-Veikko Wettenhovi}\\
        \mail{villewe@uef.fi}\\\\
\\
      \textit{In this investigation we thoroughly analyze phase errors in synthetic aperture radar data, comparing our results to classic autofocusing algorithms, and propose a joint image formation and phase estimation algorithm based on high order total variation and phase synchronization. Our technique models the true correlation of phase errors, while enforcing smoothness and sharpness of edges within the scene. Numerical results show that our autofocusing technique is robust to various phase errors, phase wrappings, and noise. }\\
\\ 
        \myaut{*   Theresa Scarnati}\\
        \mail{tscarnati24@gmail.com}\\\\
        \myaut{  Anne Gelb}\\
        \mail{anne.e.gelb@dartmouth.edu}\\\\
\\
      \textit{High energy X-ray diffraction data collected in-situ during loading experiments permits probing crystal structure of a plastically deforming material sample. The proposed image representation assumes the intensity signal to be a sparse nonnegative superposition of Gaussian basis functions drawn from an over-complete dictionary and facilitates analysis of data from material with arbitrary crystal granularity. The representation is shown to capture data morphology and reveal information about the sample’s processing history in experimental data.}\\
\\ 
        \myaut{*   Daniel Banco}\\
        \mail{daniel.banco@tufts.edu}\\\\
        \myaut{  Eric Miller}\\
        \mail{eric.miller@tufts.edu}\\\\
        \myaut{  Matthew Miller}\\
        \mail{matthew.miller@cornell.edu}\\\\
        \myaut{  Armand Beaudoin}\\
        \mail{beaudoia@gmail.com}\\\\
\\
      \textit{For texture images, the inpainting problem can be formulated as a random field conditional simulation within the masked area given the unmasked pixels.
We propose such an approach for stationary Gaussian textures and show that the traditional algorithm for Gaussian conditional simulation can be implemented efficiently using the Fourier representation of the covariance operator. 
The resulting algorithm is able to inpaint large holes of any shape in a texture.
Joint work with Arthur Leclaire ; http://epubs.siam.org/doi/10.1137/16M1109047}\\
\\ 
        \myaut{*   Bruno Galerne}\\
        \mail{bruno.galerne@parisdescartes.fr}\\\\
        \myaut{  Arthur Leclaire}\\
        \mail{arthur.leclaire@cmla.ens-cachan.fr}\\\\
\\
      \textit{Raman images are restored using constrained interior point least squares (C-IPLS). Nonnegative source separation reduces the dimensionality of the data cube, substantially decreasing computation time. C-IPLS is then simultaneously applied to all resulting map images with each weighted sum over co-localised pixel constrained to positivity. The respective weights are determined by the separated sources. Joint positivity significantly improves the quality of physical characterisation and spatial resolution is enhanced from 400nm to better than 50nm.}\\
\\ 
        \myaut{*   Dominik J. Winterauer}\\
        \mail{dominik.winterauer@renishaw.com}\\\\
\\
      \textit{[Joint work with Gero Friesecke] We consider phase retrieval on the space of square integrable functions. Assuming object space knowledge of the image (such as positivity or support), we show that the Error-Reduction algorithm may be viewed as a discretized gradient flow (without the need to explicitly impose object space constraints). We use this setting to analyze convergence properties of the Error-Reduction algorithm and propose a novel Error-Reduction variant that outperforms standard algorithms.}\\
\\ 
        \myaut{*   Tsipenyuk Arseniy}\\
        \mail{arseniy.tsipenyuk@mytum.de}\\\\
        \myaut{  Gero Friesecke}\\
        \mail{gf@ma.tum.de}\\\\
\\
      \textit{The inverse problem of elastic scattering by an impenetrable obstacle surrounded by a piecewise homogeneous medium is studied. The corresponding direct scattering problem is mathematically modeled and well-posedness issues are discussed. An essential mixed reciprocity relation is given, uniqueness results for the determination of the impenetrable obstacle with its physical property are proved, and last but not least, the unique determination of the penetrable interface contains the obstacle in its interior is also established.     
 }\\
\\ 
        \myaut{*   Vassilios Sevroglou}\\
        \mail{bsevro@unipi.gr}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 9}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{To compute shape from a sequence of defocused images, we make a connection between the geometrical approach of Favaro et al.  and frame theory, interpreting  defocusing operators as analysis operators of  frames.  In order to solve the inverse problem we impose regularization conditions with respect to frame decompositions in a cosparse setting and solve two minimization problems - one for dictionary learning, one for reconstructing the shape.}\\
\\ 
        \myaut{*   Anastasia Zakharova}\\
        \mail{anastasia.zakharova@insa-rouen.fr}\\\\
\\
      \textit{The superposition of the  signal from a blurred illumination results in partially coherent measurements. Here we propose the Gradient Decomposition of the Probe (GDP), a model that exploits the blurring kernel separability. We describe a first-order splitting algorithm GDP-ADMM to solve the .non-linear blind partially coherent phase retrieval problem. Remarkably, GDP-ADMM produces satisfactory results even when the ratio between kernel and beam size is more than one, or or when the distance between successive acquisitions is almost twice as large as the beam width.}\\
\\ 
        \myaut{*   Stefano Marchesini}\\
        \mail{smarchesini@lbl.gov}\\\\
        \myaut{  Huibin Chang}\\
        \mail{huibinchang@lbl.gov}\\\\
        \myaut{  Pablo Enfedaque}\\
        \mail{penfedaque@lbl.gov}\\\\
        \myaut{  Hari Krishnan}\\
        \mail{hkrishnan@lbl.gov}\\\\
\\
      \textit{To define a dissimilarity measure between geometrical structures, we propose to use a representation of shapes with normal cycles (an object associated with the normal bundle of the shape which encodes all the curvature information). Using kernel metrics on normal cycles, we define a metric between shapes that fits in a framework of inexact registration. It allows for a matching that takes into account the region of high curvature and the boundaries of the shapes.}\\
\\ 
        \myaut{*   Roussillon Pierre}\\
        \mail{roussillon.pierre@gmail.com}\\\\
\\
      \textit{Recently, coded masks have been used to demonstrate a thin form-factor lensless camera, FlatCam, in which a mask is placed immediately on top of a bare image sensor. We present an imaging model and algorithm to jointly estimate depth and intensity information in the scene from a single or multiple FlatCams. We use a lightfield representation for 3D imaging model and a greedy algorithm for joint depth and image recovery. }\\
\\ 
        \myaut{*   Salman Asif Asif}\\
        \mail{sasif@ece.ucr.edu}\\\\
\\
      \textit{The cone-beam tomography consists of integrating a function defined on the three-dimensional space along every ray that starts on a certain scanning curve. Based on Grangeat's formula, Louis [2016, Inverse Problems, 32 115005] states a reconstruction formula based on a new generalized Funk-Radon transform. In this talk, we give a singular value decomposition of this generalized Funk-Radon transform and discuss its application to the cone-beam integrals.}\\
\\ 
        \myaut{*   Michael Quellmalz}\\
        \mail{michael.quellmalz@mathematik.tu-chemnitz.de}\\\\
\\
      \textit{We discuss continued development of a compact one-dimensional imaging interferometer array implemented on a photonic integrated circuit. Two-dimensional images were reconstructed from observations of test scenes at different angles.
This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA). The views, opinions and/or findings expressed are those of the author(s) and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government.}\\
\\ 
        \myaut{*   Samuel Thurman}\\
        \mail{sam.t.thurman@lmco.com}\\\\
        \myaut{  Katherine Badham}\\
        \mail{katherine.e.badham@lmco.com}\\\\
        \myaut{  Alan Duncan}\\
        \mail{alan.duncan@lmco.com}\\\\
        \myaut{  Chad Ogden}\\
        \mail{chad.e.ogden@lmco.com}\\\\
        \myaut{  Guy Chriqui}\\
        \mail{guy.chriqui@lmco.com}\\\\
        \myaut{  Richard Kendrick}\\
        \mail{richard.l.kendrick@raytheon.com}\\\\
        \myaut{  Danielle Wuchenich}\\
        \mail{danielle.wuchenich@lmco.com}\\\\
        \myaut{  Tiehui Su}\\
        \mail{tiesu@ucdavis.edu}\\\\
        \myaut{  S. J. B. Yoo}\\
        \mail{sbyoo@ucdavis.edu}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 10}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{We present different methods to reconstruct an unknown compact sound profile embedded in a random noisy background medium, given measurements of the scattered field and information about the probability distribution of the background medium and the sound profile. In the methods presented, we apply the Gauss-Newton method with the recursive linearization algorithm. A fast direct solver is used to speed-up the solution of the forward model, which allowed simulations with thousands of samples.}\\
\\ 
        \myaut{*   Carlos Borges}\\
        \mail{borges@ices.utexas.edu}\\\\
        \myaut{  George Biros}\\
        \mail{biros@ices.utexas.edu}\\\\
\\
      \textit{We present an algorithm for approximating a function defined over a manifold utilizing only noisy function values at locations sampled from the manifold with noise. To produce the approximation we do not require any knowledge regarding the manifold other than its dimension. The approximation scheme is based upon the Manifold Moving Least-Squares (MMLS). We compare, using numerical experiments, the presented algorithm to state-of-the-art algorithms for regression over manifolds and show its resistans to noise.}\\
\\ 
        \myaut{  Yariv Aizenbud}\\
        \mail{aizeny@post.tau.ac.il}\\\\
        \myaut{*   Barak Sober}\\
        \mail{baraksov@post.tau.ac.il}\\\\
\\
      \textit{We propose a variational framework for the three-dimensional volume reconstruction from 2-D slices. The proposed method is based on modified Cahn-Hilliard equation. For keeping constraints accurately as well as obtaining a smooth result, we propose pre-smoothing procedure. After splitting a grayscale image into binary channels, we perform binary inpainting. Then we introduce smoothing and shock filter when combining binary results. We applied our results for construction of 3-D human body from slices of CT images.}\\
\\ 
        \myaut{*   Junwoo Kim}\\
        \mail{kjw8707@kaist.ac.kr}\\\\
        \myaut{  Chang-Ock Lee}\\
        \mail{colee@kaist.edu}\\\\
\\
      \textit{The cardiac electrical activity can be described through a semilinear parabolic equation coupled with nonlinear ODE, together with a passive conductor model of the torso.
We aim at indentifying ischemias, i.e. regions where the coefficients of the equations describing the cardiac electrical activity are altered, taking advantage of data acquired on the boundary of the torso. 
For this purpose, we formulate a constraint optimization problem with Total-Variation regularization and adopt a phase-field approach.}\\
\\ 
        \myaut{*   Luca Ratti}\\
        \mail{luca.ratti@polimi.it}\\\\
        \myaut{  Elena Beretta}\\
        \mail{elena.beretta@polimi.it}\\\\
        \myaut{  Marco Verani}\\
        \mail{marco.verani@polimi.it}\\\\
\\
      \textit{We consider the reconstruction of a 3D object from measurements of liquid displacement, exploiting Archimedes law. These measurements are obtained by draining fluid from a container while the object is placed inside in various angles. The reconstruction is obtained by fitting simulations to the measurements, which leads to an inverse problem. To impose proper regularization, we use a parametric level set approach. We show that this way the reconstruction is obtained more accurately and efficiently than with other common approaches. }\\
\\ 
        \myaut{*   Eran Treister}\\
        \mail{erant@bgu.ac.il}\\\\
        \myaut{  Andrei Sharf}\\
        \mail{asharf@cs.bgu.ac.il}\\\\
\\
      \textit{Radio astronomy imaging has been primarily focused on a planar approximation to a portion of the observed sphere. We present an efficient algorithm that reconstructs directly on the celestial sphere. It leverages an analytic Hilbert space framework to produce a continuous image description that may be stored independently of resolution, and sampled up to the fundamental limit of the telescope. The algorithm is inherently simpler and more intuitive than previous methods, as well as faster.}\\
\\ 
        \myaut{*   Paul Hurley}\\
        \mail{pah@zurich.ibm.com}\\\\
        \myaut{  Matthieu Simeoni}\\
        \mail{matthieu.simeoni@epfl.ch}\\\\
\\
\end{multicols}
  \noindent\textbf{CP Contributed session 11}\\
  \textit{} \\
    
  \begin{multicols}{2}
      \textit{A stochastic extension of Navier's equations of elasticity is considered that accounts for uncertainties in the domain and material parameters. We consider a setting where a set of measurement data is combined with a simulated surrogate model formed using sparse grid stochastic collocation. By using this approach, we obtain a solution that recovers both the simulated model and the set of measurements. The accuracy of this approach is discussed both theoretically and in numerical experiments.}\\
\\ 
        \myaut{*   Vesa Kaarnioja}\\
        \mail{vesa.kaarnioja@helsinki.fi}\\\\
        \myaut{  Harri Hakula}\\
        \mail{harri.hakula@aalto.fi}\\\\
\\
      \textit{Time-variant inverse problems are naturally cast as state space problems. In state estimation, using a smoother as the estimator results in a smaller estimation errors than a Kalman-type filter. However, this induces an augmented high-dimensional problem. To deal with this challenge, we construct a reduced state space model incorporating approximation errors. We derive the corresponding fixed-lag smoother and apply to an imaging problem induced by a stochastic advection-diffusion equation with unknown temporal boundary conditions.}\\
\\ 
        \myaut{*   Pascal Eun Sig Cheon}\\
        \mail{pascal.cheon@auckland.ac.nz}\\\\
\\
      \textit{Hierarchical conditionally Gaussian priors, combined with efficient iterative solvers of linear systems, provide an efficient tool for solving inverse imaging problems in which the unknown is believed to be a blocky image. In this talk, we discuss how these methods can be used to guide targeted mesh refinement in imaging problems involving finite element computations.}\\
\\ 
        \myaut{*   Anna Cosmo}\\
        \mail{cosmo.anna@libero.it}\\\\
\\
      \textit{Analytic methods of solving inverse problems to recover optical properties turbid media from optical imaging data require that the RTE be solved numerous times.  Therefore, computation time of these methods is limited by the optimization method used and the computation time.  We present a novel method for approximating RTE solutions which provides similar accuracy to the standard spherical harmonic method with a significant time reduction.  We show a comparison using Spatial Frequency Domain Imaging data.}\\
\\ 
        \myaut{*   Sean Horan}\\
        \mail{sthoran@uci.edu}\\\\
        \myaut{  Vasan Venugopalan}\\
        \mail{vvenugop@uci.edu}\\\\
\\
      \textit{Electron backscatter diffraction (EBSD) is an imaging technique which allows to detect crystal orientations at the surface of a polycrystalline material. Crystal orientations are represented by elements of the three dimensional group $SO(3)$ modulo crystal symmetries from finite subgroup $S$ of $SO(3)$. In this talk we address the issue of nicely embed the quotient $SO(3)/S$ into the three dimensional color space, which is crucial for displaying and analyzing orientation values images.}\\
\\ 
        \myaut{*   Hielscher Ralf}\\
        \mail{ralf.hielscher@mathematik.tu-chemnitz.de}\\\\
\\
      \textit{Blob detection has great applications in cellular microscopic image analysis. We present a new method to filter closely located microorganisms. We adopt counter harmonic mean to calculate robustly morphological operations. Then approximate a single-pixel-wide line structuring element by a flattened Gaussian structuring element function. The maximum of the pseudo-morphologically opened images is calculated, and subtracted from the input image. Our method achieves effective detection of close blobs without shape constraints and needs not rotate image.}\\
\\ 
        \myaut{*   Yongjian Yu}\\
        \mail{yongjian.yu@axonconnected.com}\\\\
        \myaut{  Jue Wang}\\
        \mail{wangj@union.edu}\\\\
\\
      \textit{In this paper, a parallel integro-differential approach to
the solution of the 3-D subsurface scattering problem is presented. The method is a
further development of the previously proposed by author and his colloquies
computational algorithm for the recovery of unknown coefficient in the
2D Helmholtz Equation. The reconstructed images represent the electromagnetic properties of the respective underground regions. A parallel implementation of the developed method is main novel elements in the proposed computational
framework.}\\
\\ 
        \myaut{*   Yury Gryazin}\\
        \mail{gryazin@isu.edu}\\\\
\\
\end{multicols}

